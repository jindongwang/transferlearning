# Awesome papers by date

Here, we list some papers related to transfer learning by date (starting from 2021-07). For papers older than 2021-07, please refer to the [papers by topic](awesome_paper.md), which contains more papers.

- [Awesome papers by date](#awesome-papers-by-date)
  - [2023-01](#2023-01)
  - [2022-12](#2022-12)
  - [2022-11](#2022-11)
  - [2022-10](#2022-10)
  - [2022-09](#2022-09)
  - [2022-08](#2022-08)
  - [2022-07](#2022-07)
  - [2022-06](#2022-06)
  - [2022-05](#2022-05)
  - [2022-04](#2022-04)
  - [2022-03](#2022-03)
  - [2022-02](#2022-02)
  - [2022-01](#2022-01)
  - [2021-12](#2021-12)
  - [2021-11](#2021-11)
  - [2021-10](#2021-10)
  - [2021-09](#2021-09)
  - [2021-08](#2021-08)
  - [2021-07](#2021-07)

## 2023-01

- ICLR'23 FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning [[arxiv](https://arxiv.org/abs/2205.07246)]
  - New baseline for semi-supervised learning 半监督学习新算法

- CLIP the Gap: A Single Domain Generalization Approach for Object Detection [[arxiv](https://arxiv.org/abs/2301.05499)]
  - Using CLIP for domain generalization object detection 使用CLIP进行域泛化的目标检测

- Language-Informed Transfer Learning for Embodied Household Activities [[arxiv](https://arxiv.org/abs/2301.05318)]
  - Transfer learning for robust control in household 在家居机器人上使用强化迁移学习

- Does progress on ImageNet transfer to real-world datasets? [[arxiv](https://arxiv.org/abs/2301.04644)]
  - ImageNet accuracy does not transfer to down-stream tasks

- TPAMI'23 Source-Free Unsupervised Domain Adaptation: A Survey [[arxiv](http://arxiv.org/abs/2301.00265)]
  - A survey on source-free domain adaptation 关于source-free DA的一个最新综述

- Discriminative Radial Domain Adaptation [[arxiv](http://arxiv.org/abs/2301.00383)]
  - Discriminative radial domain adaptation 判别性的放射式domain adaptation

## 2022-12

- WACV'23 Cross-Domain Video Anomaly Detection without Target Domain Adaptation [[arxiv](https://arxiv.org/abs/2212.07010)]
  - Cross-domain video anomaly detection without target domain adaptation 跨域视频异常检测

- Co-Learning with Pre-Trained Networks Improves Source-Free Domain Adaptation [[arxiv](https://arxiv.org/abs/2212.07585)]
  - Pre-trained models for source-free domain adaptation 用预训练模型进行source-free DA

- TMLR'22 A Unified Survey on Anomaly, Novelty, Open-Set, and Out of-Distribution Detection: Solutions and Future Challenges [[openreview](https://openreview.net/forum?id=aRtjVZvbpK)]
  - A recent survey on OOD/anomaly detection 一篇最新的关于OOD/anomaly detection的综述

- NeurIPS'18 A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks [[paper](https://proceedings.neurips.cc/paper/2018/hash/abdeb6f575ac5c6676b747bca8d09cc2-Abstract.html)]
  - Using class-conditional distribution for OOD detection 使用类条件概率进行OOD检测

- ICLR'22 Discrete Representations Strengthen Vision Transformer Robustness [[arxiv](http://arxiv.org/abs/2111.10493)]
  - Embed discrete representation for OOD generalization 在ViT中加入离散表征增强OOD性能

- CONDA: Continual Unsupervised Domain Adaptation Learning in Visual Perception for Self-Driving Cars [[arxiv](https://arxiv.org/abs/2212.00621)]
  - Continual DA for self-driving cars 连续的domain adaptation用于自动驾驶

- Finetune like you pretrain: Improved finetuning of zero-shot vision models [[arxiv]](http://arxiv.org/abs/2212.00638)]
  - Improved fine-tuning of zero-shot models 针对zero-shot model提高fine-tuneing

## 2022-11

- ECCV-22 DecoupleNet: Decoupled Network for Domain Adaptive Semantic Segmentation [[arXiv](https://arxiv.org/pdf/2207.09988.pdf)] [[Code](https://github.com/dvlab-research/DecoupleNet)]
  - Domain adaptation in semantic segmentation 语义分割域适应

- Robust Mean Teacher for Continual and Gradual Test-Time Adaptation [[arxiv](https://arxiv.org/abs/2211.13081)]
  - Mean teacher for test-time adaptation 在测试时用mean teacher进行适配

- Learning to Learn Domain-invariant Parameters for Domain Generalization [[arxiv](Learning to Learn Domain-invariant Parameters for Domain Generalization)]
  - Learning to learn domain-invariant parameters for DG 元学习进行domain generalization

- HMOE: Hypernetwork-based Mixture of Experts for Domain Generalization [[arxiv](https://arxiv.org/abs/2211.08253)]
  - Hypernetwork-based ensembling for domain generalization 超网络构成的集成学习用于domain generalization

- The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning [[arxiv](https://arxiv.org/abs/2106.15831)]
  - OOD using fine-tuning 系统总结了基于fine-tuning进行OOD的一些结果

- GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective [[arxiv](https://arxiv.org/abs/2211.08073)]
  - OOD for natural language processing evaluation 提出GLUE-X用于OOD在NLP数据上的评估

- CVPR'22 Delving Deep Into the Generalization of Vision Transformers Under Distribution Shifts [[arxiv](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.html)]
  - Vision transformers generalization under distribution shifts 评估ViT的分布漂移

- NeurIPS'22 Models Out of Line: A Fourier Lens on Distribution Shift Robustness [[arxiv](https://openreview.net/forum?id=YZ-N-sejjwO)]
  - A fourier lens on distribution shift robustness 通过傅里叶视角来看分布漂移的鲁棒性

- CVPR'22 Does Robustness on ImageNet Transfer to Downstream Tasks? [[arxiv](https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.pdf)]
  - Does robustness on imagenet transfer lto downstream tasks?

- Normalization Perturbation: A Simple Domain Generalization Method for Real-World Domain Shifts [[arxiv](https://arxiv.org/abs/2211.04393)]
  - Normalization perturbation for domain generalization 通过归一化扰动来进行domain generalization

- FIXED: Frustraitingly easy domain generalization using Mixup [[arxiv](https://arxiv.org/pdf/2211.05228.pdf)]
  - 使用Mixup进行domain generalization

- Learning to Learn Domain-invariant Parameters for Domain Generalization [[arxiv](https://arxiv.org/abs/2211.04582)]
  - Learning to learn domain-invariant parameters for domain generalization

- NeurIPS'22 Improved Fine-Tuning by Better Leveraging Pre-Training Data [[openreview](https://openreview.net/forum?id=YTXIIc7cAQ)]
  - Using pre-training data for fine-tuning 用预训练数据来做微调

- NeurIPS'22 Divide and Contrast: Source-free Domain Adaptation via Adaptive Contrastive Learning [[openreview](https://openreview.net/forum?id=NjImFaBEHl)]
  - Adaptive contrastive learning for source-free DA 自适应的对比学习用于source-free DA

- NeurIPS'22 LOG: Active Model Adaptation for Label-Efficient OOD Generalization [[openreview](https://openreview.net/forum?id=VdQWVdT_8v)]
  - Model adaptation for label-efficient OOD generalization

- NeurIPS'22 MetaTeacher: Coordinating Multi-Model Domain Adaptation for Medical Image Classification [[openreview](https://openreview.net/forum?id=AQd4ugzALQ1)]
  - Multi-model domain adaptation mor medical image classification 多模型DA用于医疗数据

- NeurIPS'22 Domain Adaptation under Open Set Label Shift [[openreview](https://openreview.net/forum?id=OMZG4vsKmm7)]
  - Domain adaptation under open set label shift 在开放集的label shift中的DA

- NeurIPS'22 Domain Generalization without Excess Empirical Risk [[openreview](https://openreview.net/forum?id=pluyPFTiTeJ)]
  - Domain generalization without excess empirical risk 

- NeurIPS'22 FedSR: A Simple and Effective Domain Generalization Method for Federated Learning [[openreview](https://openreview.net/forum?id=mrt90D00aQX)]
  - FedSR for federated learning domain generalization 用于联邦学习的domain generalization

- NeurIPS'22 Probable Domain Generalization via Quantile Risk Minimization [[openreview](https://openreview.net/forum?id=6FkSHynJr1)]
  - Domain generalization with quantile risk minimization 用quantile风险最小化的domain generalization

- NeurIPS'22 Beyond Not-Forgetting: Continual Learning with Backward Knowledge Transfer [[arxiv](http://arxiv.org/abs/2211.00789)]
  - Continual learning with backward knowledge transfer 反向知识迁移的持续学习

- NeurIPS'22 Test Time Adaptation via Conjugate Pseudo-labels [[openreview](https://openreview.net/forum?id=2yvUYc-YNUH)]
  - Test-time adaptation with conjugate pseudo-labels 用伪标签进行测试时adaptation

- NeurIPS'22 Your Out-of-Distribution Detection Method is Not Robust! [[openreview](https://openreview.net/forum?id=YUEP3ZmkL1)]
  - OOD models are not robust 分布外泛化模型不够鲁棒


## 2022-10

- NeurIPS'22 Respecting Transfer Gap in Knowledge Distillation [[arxiv](http://arxiv.org/abs/2210.12787)]
  - Transfer gap in distillation 知识蒸馏中的迁移gap

- Transfer of Machine Learning Fairness across Domains [[arxiv](http://arxiv.org/abs/1906.09688)]
  - Fairness transfer in transfer learning 迁移学习中的公平性迁移

- On Fine-Tuned Deep Features for Unsupervised Domain Adaptation [[arxiv](http://arxiv.org/abs/2210.14083)]
  - Fine-tuned features for domain adaptation 微调的特征用于域自适应

- WACV-23 ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing [[arxiv](https://arxiv.org/abs/2210.11539)]
  - Domain adaptation for object detection using confidence mixing 用置信度mix做domain adaptation

- CVPR-20 Regularizing CNN Transfer Learning With Randomised Regression [[arxiv](https://openaccess.thecvf.com/content_CVPR_2020/html/Zhong_Regularizing_CNN_Transfer_Learning_With_Randomised_Regression_CVPR_2020_paper.html)]
  - Using randomized regression to regularize CNN 用随机回归约束CNN迁移学习

- AAAI-21 TransTailor: Pruning the Pre-trained Model for Improved Transfer Learning [[arxiv](https://ojs.aaai.org/index.php/AAAI/article/view/17046)]
  - Pruning pre-trained model for transfer learning 通过对预训练模型进行剪枝来进行迁移学习

- PhDthesis Generalizing in the Real World with Representation Learning [[arxiv](http://arxiv.org/abs/2210.09925)]
  - A phd thesis about generalization in real world 一篇关于现实世界如何做Generalization的博士论文

- The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning [[arxiv](https://openreview.net/forum?id=Qs3EfpieOh)]
  - Evolution of OOD robustness by fine-tuning 

- Visual Prompt Tuning for Test-time Domain Adaptation [[arxiv](http://arxiv.org/abs/2210.04831)]
  - VPT for test-time adaptation 用prompt tuning进行test-time DA

- Unsupervised Domain Adaptation for COVID-19 Information Service with Contrastive Adversarial Domain Mixup [[arxiv](https://arxiv.org/abs/2210.03250)]
  - Domain adaptation for COVID-19 用DA进行COVID-19预测

- ICONIP'22 IDPL: Intra-subdomain adaptation adversarial learning segmentation method based on Dynamic Pseudo Labels [[arxiv](https://arxiv.org/abs/2210.03435)]
  - Intra-domain adaptation for segmentation 子领域对抗Adaptation

- NeurIPS'22 Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks [[arxiv](https://arxiv.org/abs/2210.03265)]
  - Parameter-efficient multi-task adaptation 参数高效的多任务adaptation

- Out-of-Distribution Generalization in Algorithmic Reasoning Through Curriculum Learning [[arxiv](https://arxiv.org/abs/2210.03275)]
  - OOD in algorithmic reasoning 算法reasoning过程中的OOD

- Towards Out-of-Distribution Adversarial Robustness [[arxiv](https://arxiv.org/abs/2210.03150)]
  - OOD adversarial robustness OOD对抗鲁棒性

- TripleE: Easy Domain Generalization via Episodic Replay [[arxiv](https://arxiv.org/pdf/2210.01807.pdf)]
  - Easy domain generalization by episodic replay

- Deep Spatial Domain Generalization [[arxiv](https://web7.arxiv.org/pdf/2210.00729.pdf)]
  - Deep spatial domain generalization

## 2022-09

- Assaying Out-Of-Distribution Generalization in Transfer Learning [[arXiv](http://arxiv.org/abs/2207.09239)]
  - A lot of experiments to show OOD performance 

- ICML-21 Accuracy on the Line: on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization [[arxiv](https://proceedings.mlr.press/v139/miller21b.html)]
  - Strong correlation between ID and OOD

- Deep Domain Adaptation for Detecting Bomb Craters in Aerial Images [[arxiv](https://arxiv.org/abs/2209.11299)]
  - Bomb craters detection using domain adaptation 用DA检测遥感图像中的炮弹弹坑

- WACV-23 TeST: Test-time Self-Training under Distribution Shift [[arxiv](https://arxiv.org/abs/2209.11459)]
  - Test-time self-training 测试时训练

- StyleTime: Style Transfer for Synthetic Time Series Generation [[arxiv](https://arxiv.org/abs/2209.11306)]
  - Style transfer for time series generation 时间序列生成的风格迁移

- Robust Domain Adaptation for Machine Reading Comprehension [[arxiv](https://arxiv.org/abs/2209.11615)]
  - Domain adaptation for machine reading comprehension 机器阅读理解的domain adaptation

- Generalized representations learning for time series classification [[arxiv](https://arxiv.org/abs/2209.07027)]
  - OOD for time series classification 域泛化用于时间序列分类

- USB: A Unified Semi-supervised Learning Benchmark [[arxiv](https://arxiv.org/abs/2208.07204)] [[code](https://github.com/microsoft/Semi-supervised-learning)]
  - Unified semi-supervised learning codebase 半监督学习统一代码库

- Test-Time Training with Masked Autoencoders [[arxiv](https://arxiv.org/abs/2209.07522)]
  - Test-time training with MAE MAE的测试时训练

- Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models [[arxiv](https://arxiv.org/abs/2209.07511)]
  - Test-time prompt tuning 测试时的prompt tuning

- TeST: test-time self-training under distribution shift [[arxiv](https://assets.amazon.science/02/1c/b469914c4732a9c29ac765f948f9/test-test-time-self-training-under-distribution-shift.pdf)]
  - Test-time self-training 测试时的self-training

- Language-aware Domain Generalization Network for Cross-Scene Hyperspectral Image Classification [[arxiv](https://arxiv.org/pdf/2209.02700.pdf)]
  - Domain generalization for cross-scene hyperspectral image classification 域泛化用于高光谱图像分类

- IEEE-TMM'22 Uncertainty Modeling for Robust Domain Adaptation Under Noisy Environments [[IEEE](https://ieeexplore.ieee.org/abstract/document/9882310)]
  - Uncertainty modeling for domain adaptation 噪声环境下的domain adaptation

- Improving Robustness to Out-of-Distribution Data by Frequency-based Augmentation [arxiv](https://arxiv.org/abs/2209.02369)
  - OOD by frequency-based augmentation 通过基于频率的数据增强进行OOD

- Domain Generalization for Prostate Segmentation in Transrectal Ultrasound Images: A Multi-center Study [arxiv](https://arxiv.org/abs/2209.02126)
  - Domain generalizationfor prostate segmentation 领域泛化用于前列腺分割

- Domain Adaptation from Scratch [arxiv](https://arxiv.org/abs/2209.00830)
  - Domain adaptation from scratch

- Towards Optimization and Model Selection for Domain Generalization: A Mixup-guided Solution [arxiv](https://arxiv.org/abs/2209.00652)
  - Model selection for domain generalization 域泛化中的模型选择问题

- [Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets](https://arxiv.org/pdf/2208.07463.pdf)
  - Parameter efficient CNN adapter for transfer learning 参数高效的CNN adapter用于迁移学习

- [Equivariant Disentangled Transformation for Domain Generalization under Combination Shift](https://arxiv.org/abs/2208.02011)
  - Equivariant disentangled transformation for domain generalization 新的建模domain generalization的思路

## 2022-08

- ECCV-22 workshop [Domain-Specific Risk Minimization](https://arxiv.org/abs/2208.08661)
  - Domain-specific risk minization for OOD 领域特异性风险最小化用于域泛化

- TPAMI [Semi-Supervised and Unsupervised Deep Visual Learning: A Survey](https://arxiv.org/abs/2208.11296)
  - Survey on semi and unsupervsed learning 半监督和无监督综述

- [Improving video retrieval using multilingual knowledge transfer](https://arxiv.org/abs/2208.11553)
  - Video retrieval using multilingual knowledge transfer 多语言知识迁移用于视频检索

- [Transfer Learning-based State of Health Estimation for Lithium-ion Battery with Cycle Synchronization](https://arxiv.org/abs/2208.11204)
  - Battery health estimation using transfer learning 用迁移学习进行电池健康估计

- IJCAI-22 [Domain Generalization through the Lens of Angular Invariance](https://www.ijcai.org/proceedings/2022/0139.pdf)
  - Using angular invariance for domain generalization 使用角度不变性进行domain generalization

- MM-22 [Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation](https://arxiv.org/abs/2208.01195)
  - Transformer for domain adaptation 用transformer进行DA

- [Adaptive Domain Generalization via Online Disagreement Minimization](https://arxiv.org/abs/2208.01996)
  - Online domain generalization via disagreement minimization 在线DG

- [Self-Distilled Vision Transformer for Domain Generalization](http://arxiv.org/abs/2207.12392)
  - Vision transformer for domain generalization 用ViT做domain generalization

- NeurIPS-21 [The balancing principle for parameter choice in distance-regularized domain adaptation](https://papers.nips.cc/paper/2021/hash/ae0909a324fb2530e205e52d40266418-Abstract.html)
  - Hyperparameter selection for domain adaptation 对adaptation中的正则项系数进行选择

- [Transfer Learning for Segmentation Problems: Choose the Right Encoder and Skip the Decoder](https://arxiv.org/abs/2207.14508)
  - Transfer learning for segmentation problems 统一表示迁移学习于分割问题的思路

## 2022-07 

- TMLR-22 [Domain-invariant Feature Exploration for Domain Generalization](https://arxiv.org/abs/2207.12020)
  - Exploring domain-invariant feature for domain generalization 探索领域不变特征在领域泛化中的应用

- TIST-22 [Domain Generalization for Activity Recognition via Adaptive Feature Fusion](https://arxiv.org/abs/2207.11221)
  - Domain generalization for activity recognition 领域泛化用于行为识别

- ECCV-22 [Prototype-Guided Continual Adaptation for Class-Incremental Unsupervised Domain Adaptation](https://arxiv.org/abs/2207.10856)
  - Prototype continual domain adaptation 基于原型的类增量domain adaptation

- [Federated Semi-Supervised Domain Adaptation via Knowledge Transfer](https://arxiv.org/abs/2207.10727)
  - Federated semi-supervised DA 联邦半监督DA

- [Hyper-Representations for Pre-Training and Transfer Learning](https://arxiv.org/abs/2207.10951)
  - Hyper-representation for pre-training and fine-tuning 对于预训练和微调的超表示

- MM-22 [Source-Free Domain Adaptation for Real-world Image Dehazing](https://arxiv.org/abs/2207.06644)
  - Source-free DA for image dehazing 无需源域的迁移用于图像去雾

- [Improved OOD Generalization via Conditional Invariant Regularizer](https://arxiv.org/abs/2207.06687)
  - Improved OOD generalization via conditional invariant regularizer 通过条件不变正则进行OOD泛化

- CVPR-22 [Segmenting Across Places: The Need for Fair Transfer Learning With Satellite Imagery](https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/html/Zhang_Segmenting_Across_Places_The_Need_for_Fair_Transfer_Learning_With_CVPRW_2022_paper.html)
  - Fair transfer learning with satellite imagery 公平迁移学习

- [Transferability-Guided Cross-Domain Cross-Task Transfer Learning](https://arxiv.org/abs/2207.05510)
  - Cross-domain cross-task transfer learning 用迁移性指标指导跨领域跨任务迁移

- [Cross-Architecture Knowledge Distillation](https://arxiv.org/abs/2207.05273)
  - Cross-architecture knowledge distillation 跨架构的知识蒸馏

- ECCV-22 [Knowledge Condensation Distillation](https://arxiv.org/abs/2207.05409)
  - Knowledge condensation distillation 知识压缩蒸馏

- [An Information-Theoretic Analysis for Transfer Learning: Error Bounds and Applications](https://arxiv.org/abs/2207.05377)
  - Information-theoretic analysis for transfer learning 用信息理论解释迁移学习

- [A Data-Based Perspective on Transfer Learning](https://arxiv.org/abs/2207.05739)
  - Analyze the data numbers in transfer learning 分析迁移学习中数据的重要性

- [PAC-Bayesian Domain Adaptation Bounds for Multiclass Learners](https://arxiv.org/abs/2207.05685)
  - PAC-Bayesian domain adaptation 基于PAC-Bayesian的domain adaptation

## 2022-06

- NeurIPS-21 [Parameterized Knowledge Transfer for Personalized Federated Learning](https://proceedings.neurips.cc/paper/2021/hash/5383c7318a3158b9bc261d0b6996f7c2-Abstract.html)
  - personalized group knowledge transfer training
  - 个性化群体知识迁移
- ICML-21 [Federated Continual Learning with Weighted Inter-client Transfer](https://proceedings.mlr.press/v139/yoon21b.html)
  - Federated Weighted Inter-client Transfer (FedWeIT) for Federated Continual Learning
  - 联邦加权客户端间传输方法，用于联邦持续学习
- SIGIR-21 [FedCT: Federated Collaborative Transfer for Recommendation](https://doi.org/10.1145/3404835.3462825)
  - Federated learning for cross-domain recommendation 
  - 使用联邦迁移学习执行跨域推荐任务
- KDD-21 [Federated Adversarial Debiasing for Fair and Transferable Representations](https://doi.org/10.1145/3447548.3467281)
  - Federated Adversarial DEbiasing (FADE)
  - 通过对抗性学习对联邦学习过程去除偏见
- NeurIPS-20 [Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge](https://proceedings.neurips.cc/paper/2020/hash/a1d4c20b182ad7137ab3606f0e3fc8a4-Abstract.html)
  - Group knowledge transfer training
  - 群体知识迁移

- FL-IJCAI-22 [MetaFed: Federated Learning among Federations with Cyclic Knowledge Distillation for Personalized Healthcare](https://arxiv.org/abs/2206.08516)
  - MetaFed: a new form of federated learning 联邦之联邦学习、新范式

- Interspeech-22 [Decoupled Federated Learning for ASR with Non-IID Data](https://jd92.wang/assets/files/DecoupleFL-IS22.pdf)
  - Decoupled federated learning for non IID 解耦的联邦架构用于Non-IID语音识别

- [Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive Representation Learning](https://arxiv.org/abs/2206.10137)
  - Few-shot DA for unsupervised constrastive learning 小样本DA用于无监督对比学习

- [The Importance of Background Information for Out of Distribution Generalization](https://arxiv.org/abs/2206.08794)
  - Background information for OOD generalization 背景信息对于OOD泛化的重要性

- [Zero-Shot AutoML with Pretrained Models](https://arxiv.org/abs/2206.08476)
  - 用预训练模型进行零样本的自动机器学习 

- [How robust are pre-trained models to distribution shift?](https://arxiv.org/abs/2206.08871)
  - How robust are pre-trained models to distribution shift 评估预训练模型对于distribution shift的鲁棒性

- [FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification](https://arxiv.org/abs/2206.08671)
  - Few-shot transfer learning for image classification 小样本迁移学习用于图像分类

- [COVID-19 Detection using Transfer Learning with Convolutional Neural Network](https://arxiv.org/abs/2206.08557)
  - COVID-19 using transfer learning 用迁移学习进行COVID-19检测

- [Wav2vec-S: Semi-Supervised Pre-Training for Speech Recognition](https://arxiv.org/abs/2110.04484)
  - Pretraining for speech recognition 用预训练模型进行语音识别

- [Causal Balancing for Domain Generalization](https://arxiv.org/abs/2206.05263)
  - Causal balancing for domain generalization 因果平衡用于领域泛化

- NAACL-22 [Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning](https://arxiv.org/abs/2206.03715)
  - Transfer learning for zero-shot reasoning 迁移学习用于零次常识推理

- [ConFUDA: Contrastive Fewshot Unsupervised Domain Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2206.03888)
  - Fewshot UDA for medical image segmentation 小样本域自适应用于医疗图像分割

- [One Ring to Bring Them All: Towards Open-Set Recognition under Domain Shift](https://arxiv.org/abs/2206.03600)
  - Open set recognition with domain shift 开放集+domain shift

- [Toward Certified Robustness Against Real-World Distribution Shifts](https://arxiv.org/abs/2206.03669)
  - Certified robustness against real-world distribution shifts 真实世界中的distribution shift

- [On Transfer Learning in Functional Linear Regression](https://arxiv.org/abs/2206.04277)
  - Transfer learning in functional linear regression 迁移学习用于函数式线性回归

## 2022-05

- IJCAI-22 [Parameter-Efficient Sparsity for Large Language Models Fine-Tuning](https://arxiv.org/abs/2205.11005)
  - Parameter-efficient sparsity for language model fine-tuning 参数高效的稀疏学习用于语言模型微调

- [A Domain-adaptive Pre-training Approach for Language Bias Detection in News](https://arxiv.org/abs/2205.10773)
  - Domain-adaptive pre-training for language bias detection 领域适配预训练用于新闻语言偏见检测

- [ScholarBERT: Bigger is Not Always Better](https://arxiv.org/abs/2205.11342)
  - Empirical study on fine-tuning experiments 提出ScholarBERT进行大规模finetuning实验

- ICPR-22 [OTAdapt: Optimal Transport-based Approach For Unsupervised Domain Adaptation](https://arxiv.org/abs/2205.10738)
  - Optimal transport-based domain adaptation 利用最优传输进行领域自适应

- [Temporal Domain Generalization with Drift-Aware Dynamic Neural Network](https://arxiv.org/abs/2205.10664)
  - Temporal domain generalization with drift-aware dynamic neural network 时序域泛化

- [Active Source Free Domain Adaptation](https://arxiv.org/abs/2205.10711)
  - Active source-free DA 主动学习-无源域DA

- [Test-Time Robust Personalization for Federated Learning](https://arxiv.org/abs/2205.10920)
  - Test-time robust personalization for FL 测试时鲁棒联邦学习

- [FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning](https://arxiv.org/abs/2205.07246)
  - Self-adaptive thresholding for semi-supervised learning 新的自适应阈值半监督方法

- IJCAI-22 [Test-time Fourier Style Calibration for Domain Generalization](https://arxiv.org/abs/2205.06427)
  - Test-time calibration for domain generalization 用傅立叶变化进行域泛化的测试时矫正

- [Multiple Domain Causal Networks](https://arxiv.org/abs/2205.06791)
  - Mlutiple domain causal networks 多领域的因果网络

- ICLR-22 [Enhancing Cross-lingual Transfer by Manifold Mixup](https://arxiv.org/abs/2205.04182)
  - Cross-lingual transfer using manifold mixup 用Mixup进行cross-lingual transfer

- CVPR-22 workshop [Online Unsupervised Domain Adaptation for Person Re-identification](https://arxiv.org/abs/2205.04383)
  - Online domain adaptation for REID 在线adaptation

- [Time-Series Domain Adaptation via Sparse Associative Structure Alignment: Learning Invariance and Variance](https://arxiv.org/abs/2205.03554)
  - Time series domain adaptation 时间序列domain adaptation

- TIP-22 [Spot-adaptive Knowledge Distillation](https://arxiv.org/abs/2205.02399)
  - Spot-adaptive knowledge distillation 层次自适应的知识蒸馏

- NAACL-22 [Efficient Few-Shot Fine-Tuning for Opinion Summarization](https://arxiv.org/abs/2205.02170)
  - Few-shot fine-tuning for opinion summarization 小样本微调技术用于评论总结

- ICME-22 [Unsupervised Domain Adaptation Learning for Hierarchical Infant Pose Recognition with Synthetic Data](https://arxiv.org/abs/2205.01892)
  - Unsupervised domain adaptation for infant pose recognition 用领域自适应进行婴儿姿势识别

## 2022-04

*Updated at 2022-04-29:*

- ACL-22 [Probing Simile Knowledge from Pre-trained Language Models](https://arxiv.org/abs/2204.12807)
  - Probe simile knowledge from pre-trained model 从预训练模型中找出明喻知识

- [Parkinson's disease diagnostics using AI and natural language knowledge transfer](https://arxiv.org/abs/2204.12559)
  - Transfer learning for Parkinson's disease diagnostics 迁移学习用于帕金森诊断

- CVPR-22 [MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation](https://arxiv.org/abs/2204.12667)
  - Multi-modal test-time adaptation for 3D semantic segmentation 多模态测试时adaptation用于3D语义分割

- [Transfer Learning with Pre-trained Conditional Generative Models](https://arxiv.org/abs/2204.12833)
  - Transfer learning with pre-trained conditional generative models 条件生成模型用于迁移学习

- ICLR-22 [Towards a Unified View of Parameter-Efficient Transfer Learning](https://openreview.net/forum?id=0RDcd5Axok)
  - Unified view of parameter-efficient transfer learning 一个统一视角看待参数高效的迁移学习

- ICLR-22 [Exploring the Limits of Large Scale Pre-training](https://openreview.net/forum?id=V3C8p78sDa)
  - Many experiments to explore pre-training  许多实验来探索预训练

- IEEE TNNLS-22 [Towards Personalized Federated Learning](http://arxiv.org/abs/2103.00710)
  - A survey on personalized federated learning 一个关于个性化联邦学习的综述

- [On Effectively Learning of Knowledge in Continual Pre-training](https://arxiv.org/abs/2204.07994)
  - Continual per-training 持续的预训练

- [Just Fine-tune Twice: Selective Differential Privacy for Large Language Models](https://arxiv.org/abs/2204.07667)
  - Differential privacy by just fine-tune twice 通过微调两次进行差分隐私

- CVPR-22 [Safe Self-Refinement for Transformer-based Domain Adaptation](https://arxiv.org/abs/2204.07683)
  - Transformer-based domain adaptation 基于transformer的domain adaptation

- [Undoing the Damage of Label Shift for Cross-domain Semantic Segmentation](https://arxiv.org/abs/2204.05546)
  - Handle the label shift in cross-domain semantic segmentation  在跨域语义分割时考虑label shift

- CVPR-22 workshop [Out-Of-Distribution Detection In Unsupervised Continual Learning](https://arxiv.org/abs/2204.05462)
  - OOD detection in unsupervised continual learning 无监督持续学习中进行OOD检测

- [Transfer Learning for Autonomous Chatter Detection in Machining](https://arxiv.org/abs/2204.05400)
  - Transfer learning for autonomous chatter detection

- NAACL-22 [GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering](https://arxiv.org/abs/2204.04179)
  - Fast fine-tuning for content-based collaborative filtering
  - 快速的适用于协同过滤的微调

- AAAI-22 [Powering Finetuning in Few-shot Learning: Domain-Agnostic Feature Adaptation with Rectified Class Prototypes](https://arxiv.org/abs/2204.03749)
  - Finetuning in few-shot learning
  - 小样本学习中的微调

- CVPR-22 [Does Robustness on ImageNet Transfer to Downstream Tasks?](https://arxiv.org/abs/2204.03934)
  - Transfer learning robustness
  - 迁移学习鲁棒性

- [Blockchain as an Enabler for Transfer Learning in Smart Environments](https://arxiv.org/abs/2204.03959)
  - Blockchain transfer learning
  - 用区块链进行迁移学习

- ICLR-22 [Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution](https://openreview.net/forum?id=UYneFzXSJWh)
  - Fin-tuning and linear probing for ood generalization
  - 先linear probing最后一层再finetune对OOD任务最好

- ICLR-22 [Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks](https://openreview.net/forum?id=avgclFZ221l)
  - Asymmetry learning for OOD tasks
  - 非对称学习用于OOD任务

## 2022-03

- [Gated Domain-Invariant Feature Disentanglement for Domain Generalizable Object Detection](https://arxiv.org/abs/2203.11432)
  - Channel masking for domain generalization object detection
  - 通过一个gate控制channel masking进行object detection DG

- [A Broad Study of Pre-training for Domain Generalization and Adaptation](https://arxiv.org/abs/2203.11819)
  - A broad study of pre-training models for DA and DG
  - 大量的实验进行DA和DG

- ISPASS-22 [Benchmarking Test-Time Unsupervised Deep Neural Network Adaptation on Edge Devices](https://arxiv.org/abs/2203.11295)
  - Benchmarking test-time adaptation for edge devices
  - 在端设备上评测test-time adaptation算法

- [Multi-Source Domain Adaptation Based on Federated Knowledge Alignment](https://arxiv.org/abs/2203.11635)
  - Multi-source domain adaptation
  - 多源域自适应

- [Improving Generalization in Federated Learning by Seeking Flat Minima](https://arxiv.org/abs/2203.11834)
  - Seeking flat minima for domain generalization in federated learning
  - 通过寻找平坦值进行联邦学习领域泛化

- CVPR-22 [Decoupled Knowledge Distillation](https://arxiv.org/abs/2203.08679)
  - Decoupled knowledge distillation
  - 解耦的知识蒸馏

- [SemiPFL: Personalized Semi-Supervised Federated Learning Framework for Edge Intelligence](https://arxiv.org/abs/2203.08176)
  - Personalized federated learning
  - 个性化联邦学习

- ICSE-22 [ReMoS: Reducing Defect Inheritance in Transfer Learning via Relevant Model Slicing](https://link.zhihu.com/?target=https%3A//jd92.wang/assets/files/icse22-remos.pdf) | [Code](https://github.com/ziqi-zhang/ReMoS_artifact) | [Blog](https://zhuanlan.zhihu.com/p/446453487) | [Video](https://www.bilibili.com/video/BV1mi4y1C7bP)
  - Safe transfer learning by reducing defect inheritance
  - 安全迁移学习的最新工作

- ACL-22 [Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features](https://arxiv.org/abs/2203.03191)
  - Language-agnostic meta-learning for TTS
  - 语言无关的元学习用于TTS

- [Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models](https://arxiv.org/abs/2203.03131)
  - Adapt unfamiliar inputs to frozen pretrained models
  - 让固定的预训练模型适配不熟悉的输入

- [One Model, Multiple Tasks: Pathways for Natural Language Understanding](https://arxiv.org/abs/2203.03312)
  - Pathways for natural language understanding
  - 使用一个model用于所有NLP任务

- [Pre-trained Token-replaced Detection Model as Few-shot Learner](https://arxiv.org/abs/2203.03235)
  - Pre-trained token-replaced detection model as few-shot learner
  - 预训练的替换token的检测模型

- [Open Set Domain Adaptation By Novel Class Discovery](https://arxiv.org/abs/2203.03329)
  - Open set DA by novel class discovery
  - 基于新类发现的open set da

- ICML-21 workshop [Domain Adaptation with Factorizable Joint Shift](https://arxiv.org/abs/2203.02902)
  - Domain adaptation with factorizable joint shift
  - 基于可分解的联合漂移的领域自适应

- ICC-22 [Knowledge Transfer in Deep Reinforcement Learning for Slice-Aware Mobility Robustness Optimization](https://arxiv.org/abs/2203.03227)
  - Knowledge transfer in RL
  - 强化迁移学习

- ACL-22 [Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings](https://arxiv.org/abs/2203.00211)
  - Investigate selective prediction approaches in IID, OOD, and ADV settings
  - 在独立同分布、分布外、对抗情境中调研选择性预测方法

- PAKDD-22 [Layer Adaptive Deep Neural Networks for Out-of-distribution Detection](https://arxiv.org/abs/2203.00192)
  - Layer adaptive network for OOD detection
  - 层自适应的网络进行OOD检测

- [Learning Semantic Segmentation from Multiple Datasets with Label Shifts](https://arxiv.org/abs/2202.14030)
  - Learning semantic segmentation from many datasets with label shifts
  - 在有标签漂移的情况下从多个数据集中学习语义分割

- [Causal Domain Adaptation with Copula Entropy based Conditional Independence Test](https://arxiv.org/abs/2202.13482)
  - Use copula entropy based conditional independence test for csusal domain adaptation
  - 使用基于copula entopy的条件独立测试进行causal domain adaptation

- [Interpretable Concept-based Prototypical Networks for Few-Shot Learning](https://arxiv.org/abs/2202.13474)
  - Concept-based prototypical network for few-shot learning
  - 基于概念的原型网络用于小样本学习

## 2022-02

- [How Well Do Self-Supervised Methods Perform in Cross-Domain Few-Shot Learning?](https://arxiv.org/abs/2202.09014)
  - Self-supervised learning for cross-domain few-shot
  - 自监督用于跨领域小样本

- [Deep Transfer Learning on Satellite Imagery Improves Air Quality Estimates in Developing Nations](https://arxiv.org/abs/2202.08890)
  - Deep transfer learning for air quality estimate
  - 深度迁移学习用于卫星图到空气质量预测

- ICLR-22 oral [A Fine-Grained Analysis on Distribution Shift](https://openreview.net/forum?id=Dl4LetuLdyK)
  - Extensive experiments on distribution shift for OOD
  - 大量的实验进行OOD验证

- ICLR-22 oral [Fine-Tuning Distorts Pretrained Features and Underperforms Out-of-Distribution](https://openreview.net/forum?id=UYneFzXSJWh)
  - Fine-tuning with linear probing for OOD
  - 微调加上linear probing用于OOD

- ICLR-22 spotlight [Towards a Unified View of Parameter-Efficient Transfer Learning](https://openreview.net/pdf?id=0RDcd5Axok)
  - Detailed analysis of parameter-efficient transfer learning
  - 对参数高效的迁移学习进行分析

- ICLR-22 [Graph-Relational Domain Adaptation](https://arxiv.org/abs/2202.03628)
  - Graph-relational domain adapttion using topological structures
  - 图级别的domain adaptation，使用拓扑结构

- [Domain Adversarial Spatial-Temporal Network: A Transferable Framework for Short-term Traffic Forecasting across Cities](https://arxiv.org/abs/2202.03630)
  - Transfer learning for traffic forecasting across cities
  - 用迁移学习进行跨城市的交通流量预测

- ICLR-22 [Uncertainty Modeling for Out-of-Distribution Generalization](https://arxiv.org/abs/2202.03958)
  - Uncertainty modeling for OOD generalization
  - 用于分布外泛化的不确定性建模

- ICLR-22 [BEiT: BERT Pre-Training of Image Transformers](https://openreview.net/forum?id=p-BhZSz59o4)
  - BERT pre-training of image transformers
  - 用BERT的方式pre-train transformer

- [Improved Fine-tuning by Leveraging Pre-training Data: Theory and Practice](http://arxiv.org/abs/2111.12292)
  - Using pre-training data to improve fine-tuning
  - 使用预训练数据来帮助finetune

## 2022-01

- [IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages](https://arxiv.org/abs/2201.11732)
  - A benchmark for transfer learning in NLP
  - 一个用于NLP跨模态、任务、语言的benchmark

- [Domain generalization in deep learning-based mass detection in mammography: A large-scale multi-center study](https://arxiv.org/abs/2201.11620)
  - Domain generalization in mass detection in mammography
  - Domain generalization进行胸部射线检测

- [Domain-Invariant Representation Learning from EEG with Private Encoders](https://arxiv.org/abs/2201.11613)
  - Domain-invariant learning from EEG
  - 用于EEG信号的领域不变特征研究

- [Gap Minimization for Knowledge Sharing and Transfer](https://arxiv.org/abs/2201.11231)
  - Multitask learning with gap minimization
  - 用于多任务学习的gap minimization方法

- [DROPO: Sim-to-Real Transfer with Offline Domain Randomization](https://arxiv.org/abs/2201.08434)
  - Sim-to-real transfer with domain randomization
  - 用domain randomization进行sim-to-real transfer

- AAAI-22 [Knowledge Sharing via Domain Adaptation in Customs Fraud Detection](https://arxiv.org/abs/2201.06759)
  - Domain adaptation for fraud detection
  - 用领域自适应进行欺诈检测

- [Continual Coarse-to-Fine Domain Adaptation in Semantic Segmentation](https://arxiv.org/abs/2201.06974)
  - Domain adaptation in semantic segmentation
  - 领域自适应在语义分割的应用

- KBS-22 [Intra-domain and cross-domain transfer learning for time series data -- How transferable are the features](https://arxiv.org/abs/2201.04449)
  - An overview of transfer learning for time series data
  - 一个用迁移学习进行时间序列分析的小综述

- [A Likelihood Ratio based Domain Adaptation Method for E2E Models](2201.03655)
  - Domain adaptation for speech recognition
  - 用domain adaptation进行语音识别

- [Transfer Learning for Scene Text Recognition in Indian Languages](2201.03180)
  - Transfer learning for scene text recognition in Indian languages
  - 用迁移学习进行印度语的场景文字识别

- IEEE TMM-22 [Decompose to Adapt: Cross-domain Object Detection via Feature Disentanglement](https://arxiv.org/abs/2201.01929)
  - Invariant and shared components for Faster RCNN detection
  - 解耦公共和私有表征进行目标检测

- [Mixture of basis for interpretable continual learning with distribution shifts](https://arxiv.org/abs/2201.01853)
  - Incremental learning with mixture of basis
  - 用mixture of domains进行增量学习

- TKDE-22 [Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection](https://arxiv.org/abs/2201.00464)
  - Adaptiev memory network for anomaly detection
  - 自适应的记忆网络用于异常检测

- ICIP-22 [Meta-Learned Feature Critics for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2112.13538)
  - Meta-learning for domain generalization
  - 元学习用于domain generalization

- ICIP-22 [Few-Shot Classification in Unseen Domains by Episodic Meta-Learning Across Visual Domains](https://arxiv.org/abs/2112.13539)
  - Few-shot generalization using meta-learning
  - 用元学习进行小样本的泛化

- [Data-Free Knowledge Transfer: A Survey](https://arxiv.org/abs/2112.15278)
  - A survey on data-free distillation and source-free DA
  - 一篇关于data-free蒸馏和source-free DA的综述

- [An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification](https://arxiv.org/abs/2112.13236)
  - An ensemble of pre-trained transformer for malware classification
  - 预训练的transformer通过集成进行恶意软件检测

- [Optimal Representations for Covariate Shift](https://arxiv.org/abs/2201.00057)
  - Learning optimal representations for covariate shift
  - 为covariate shift学习最优的表达

- [Transfer-learning-based Surrogate Model for Thermal Conductivity of Nanofluids](https://arxiv.org/abs/2201.00435)
  - Transfer learning for thermal conductivity
  - 迁移学习用于热传导

- [Transfer learning of phase transitions in percolation and directed percolation](https://arxiv.org/abs/2112.15516)
  - Transfer learning of phase transitions in percolation and directed percolation
  - 迁移学习用于precolation

- [Transfer learning for cancer diagnosis in histopathological images](https://arxiv.org/abs/2112.15523)
  - Transfer learning for cancer diagnosis
  - 迁移学习用于癌症诊断

## 2021-12

- IEEE TASLP-22 [Exploiting Adapters for Cross-lingual Low-resource Speech Recognition](https://arxiv.org/abs/2105.11905)  [Zhihu article](https://zhuanlan.zhihu.com/p/448216624)
    - Cross-lingual speech recogntion using meta-learning and transfer learning
    - 用元学习和迁移学习进行跨语言的低资源语音识别

- [More is Better: A Novel Multi-view Framework for Domain Generalization](https://arxiv.org/abs/2112.12329)
    - Multi-view learning for domain generalization
    - 使用多视图学习来进行domain generalization

- [SLIP: Self-supervision meets Language-Image Pre-training](https://arxiv.org/abs/2112.12750)
    - Self-supervised learning + language image pretraining
    - 用自监督学习用于语言到图像的预训练

- [Domain Prompts: Towards memory and compute efficient domain adaptation of ASR systems](https://arxiv.org/abs/2112.08718)
  - Prompt for domain adaptation in speech recognition
  - 用Prompt在语音识别中进行domain adaptation

- [UMAD: Universal Model Adaptation under Domain and Category Shift](https://arxiv.org/abs/2112.08553)
  - Model adaptation under domain and category shift
  - 在domain和class都有shift的前提下进行模型适配

- [Domain Adaptation on Point Clouds via Geometry-Aware Implicits](https://arxiv.org/abs/2112.09343)
  - Domain adaptation for point cloud
  - 针对点云的domain adaptation

- [A Survey of Unsupervised Domain Adaptation for Visual Recognition](http://arxiv.org/abs/2112.06745)
  - A new survey article of domain adaptation
  - 对UDA的一个综述文章，来自作者博士论文

- [VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks](http://arxiv.org/abs/2112.06825)
  - Vision-language efficient transfer learning
  - 参数高校的vision-language任务迁移

- [Federated Learning with Adaptive Batchnorm for Personalized Healthcare](https://arxiv.org/abs/2112.00734)
  - Federated learning with adaptive batchnorm
  - 用自适应BN进行个性化联邦学习

- [Unsupervised Domain Adaptation: A Reality Check](https://arxiv.org/abs/2111.15672)
  - Doing experiments to show the progress of DA methods over the years
  - 用大量的实验来验证近几年来DA方法的进展

- [Hierarchical Optimal Transport for Unsupervised Domain Adaptation](https://arxiv.org/abs/2112.02073)
  - hierarchical optimal transport for UDA
  - 层次性的最优传输用于domain adaptation

- [Unsupervised Domain Generalization by Learning a Bridge Across Domains](https://arxiv.org/abs/2112.02300)
  - Unsupervised domain generalization
  - 无监督的domain generalization

- [Boosting Unsupervised Domain Adaptation with Soft Pseudo-label and Curriculum Learning](https://arxiv.org/abs/2112.01948)
  - Using soft pseudo-label and curriculum learning to boost UDA
  - 用软的伪标签和课程学习增强UDA方法

- [Subtask-dominated Transfer Learning for Long-tail Person Search](https://arxiv.org/abs/2112.00527)
  - Subtask-dominated transfer for long-tail person search
  - 子任务驱动的长尾人物搜索

- [Revisiting the Transferability of Supervised Pretraining: an MLP Perspective](https://arxiv.org/abs/2112.00496)
  - Revisit the transferability of supervised pretraining
  - 重新思考有监督预训练的可迁移性

- [Multi-Agent Transfer Learning in Reinforcement Learning-Based Ride-Sharing Systems](https://arxiv.org/abs/2112.00424)
  - Multi-agent transfer in RL
  - 在RL中的多智能体迁移

- NeurIPS-21 [On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources](https://arxiv.org/abs/2111.13822)
  - Theory and algorithm of domain-invariant learning for transfer learning
  - 对invariant representation的理论和算法

- WACV-22 [Semi-supervised Domain Adaptation via Sample-to-Sample Self-Distillation](https://arxiv.org/abs/2111.14353)
  - Sample-level self-distillation for semi-supervised DA
  - 样本层次的自蒸馏用于半监督DA

- [ROBIN : A Benchmark for Robustness to Individual Nuisancesin Real-World Out-of-Distribution Shifts](https://arxiv.org/abs/2111.14341)
  - A benchmark for robustness to individual OOD
  - 一个OOD的benchmark

- ICML-21 workshop [Towards Principled Disentanglement for Domain Generalization](https://arxiv.org/abs/2111.13839)
  - Principled disentanglement for domain generalization
  - Principled解耦用于domain generalization

## 2021-11

  - NeurIPS-21 workshop [CytoImageNet: A large-scale pretraining dataset for bioimage transfer learning](https://arxiv.org/abs/2111.11646)
    - A large-scale dataset for bioimage transfer learning
    - 一个大规模的生物图像数据集用于迁移学习
  
  - NeurIPS-21 workshop [Component Transfer Learning for Deep RL Based on Abstract Representations](https://arxiv.org/abs/2111.11525)
    - Deep transfer learning for RL
    - 深度迁移学习用于强化学习

  - NeurIPS-21 workshop [Maximum Mean Discrepancy for Generalization in the Presence of Distribution and Missingness Shift](https://arxiv.org/abs/2111.10344)
    - MMD for covariate shift
    - 用MMD来解决covariate shift问题

  - [Combined Scaling for Zero-shot Transfer Learning](https://arxiv.org/abs/2111.10050)
    - Scaling up for zero-shot transfer learning
    - 增大训练规模用于zero-shot迁移学习

  - [Federated Learning with Domain Generalization](https://arxiv.org/abs/2111.10487)
    - Federated domain generalization
    - 联邦学习+domain generalization

  - [Semi-Supervised Domain Generalization in Real World:New Benchmark and Strong Baseline](https://arxiv.org/abs/2111.10221)
    - Semi-supervised domain generalization
    - 半监督+domain generalization

  - MICCAI-21 [Domain Generalization for Mammography Detection via Multi-style and Multi-view Contrastive Learning](https://arxiv.org/abs/2111.10827)
    - Domain generalization for mammography detection
    - 领域泛化用于乳房X射线检查

  - [On Representation Knowledge Distillation for Graph Neural Networks](https://arxiv.org/abs/2111.04964)
    - Knowledge distillation for GNN
    - 适用于GNN的知识蒸馏

  - BMVC-21 [Domain Attention Consistency for Multi-Source Domain Adaptation](https://arxiv.org/abs/2111.03911)
    - Multi-source domain adaptation using attention consistency
    - 用attention一致性进行多源的domain adaptation

  - [Action Recognition using Transfer Learning and Majority Voting for CSGO](https://arxiv.org/abs/2111.03882)
    - Using transfer learning and majority voting for action recognition
    - 使用迁移学习和多数投票进行动作识别
  
  - [Open-Set Crowdsourcing using Multiple-Source Transfer Learning](https://arxiv.org/abs/2111.04073)
    - Open-set crowdsourcing using multiple-source transfer learning
    - 使用多源迁移进行开放集的crowdsourcing

  - [Improved Regularization and Robustness for Fine-tuning in Neural Networks](https://arxiv.org/abs/2111.04578)
    - Improve regularization and robustness for finetuning
    - 针对finetune提高其正则和鲁棒性

  - [TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation](https://arxiv.org/abs/2111.02682)
    - Temporal domain adaptation

  - NeurIPS-21 [Modular Gaussian Processes for Transfer Learning](https://arxiv.org/abs/2110.13515)
    - Modular Gaussian process for transfer learning
    - 在迁移学习中使用modular Gaussian过程

  - [Estimating and Maximizing Mutual Information for Knowledge Distillation](https://arxiv.org/abs/2110.15946)
    - Global and local mutual information maximation for knowledge distillation
    - 局部和全局互信息最大化用于蒸馏

  - [On Label Shift in Domain Adaptation via Wasserstein Distance](https://arxiv.org/abs/2110.15520)
    - Using Wasserstein distance to solve label shift in domain adaptation
    - 在DA领域中用Wasserstein distance去解决label shift问题

  - [Xi-Learning: Successor Feature Transfer Learning for General Reward Functions](https://arxiv.org/abs/2110.15701)
    - General reward function transfer learning in RL
    - 在强化学习中general reward function的迁移学习

  - [C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation](https://arxiv.org/abs/2110.15823)
    - Cross-modality domain adaptation for medical image segmentation
    - 跨模态的DA用于医学图像分割

  - [Deep Transfer Learning for Multi-source Entity Linkage via Domain Adaptation](https://arxiv.org/abs/2110.14509)
    - Domain adaptation for multi-source entiry linkage
    - 用DA进行多源的实体链接

  - [Temporal Knowledge Distillation for On-device Audio Classification](https://arxiv.org/abs/2110.14131)
    - Temporal knowledge distillation for on-device ASR
    - 时序知识蒸馏用于设备端的语音识别

  - [Transferring Domain-Agnostic Knowledge in Video Question Answering](https://arxiv.org/abs/2110.13395)
    - Domain-agnostic learning for VQA
    - 在VQA任务中进行迁移学习

## 2021-10

  - BMVC-21 [SILT: Self-supervised Lighting Transfer Using Implicit Image Decomposition](https://arxiv.org/abs/2110.12914)
    - Lighting transfer using implicit image decomposition
    - 用隐式图像分解进行光照迁移

  - [Domain Adaptation in Multi-View Embedding for Cross-Modal Video Retrieval](https://arxiv.org/abs/2110.12812)
    - Domain adaptation for cross-modal video retrieval
    - 用领域自适应进行跨模态的视频检索

  - [Age and Gender Prediction using Deep CNNs and Transfer Learning](https://arxiv.org/abs/2110.12633)
    - Age and gender prediction using transfer learning
    - 用迁移学习进行年龄和性别预测

  - [Domain Adaptation for Rare Classes Augmented with Synthetic Samples](https://arxiv.org/abs/2110.12216)
    - Domain adaptation for rare class
    - 稀疏类的domain adaptation

  - WACV-22 [AuxAdapt: Stable and Efficient Test-Time Adaptation for Temporally Consistent Video Semantic Segmentation](https://arxiv.org/abs/2110.12369)
    - Test-time adaptation for video semantic segmentation
    - 测试时adaptation用于视频语义分割

  - NeurIPS-21 [Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning](https://arxiv.org/abs/2110.12997)
    - Domain adaptation in reinforcement learning
    - 在强化学习中应用domain adaptation

  - WACV-21 [Domain Generalization through Audio-Visual Relative Norm Alignment in First Person Action Recognition](https://arxiv.org/abs/2110.10101)
      - Domain generalization by audio-visual alignment
      - 通过音频-视频对齐进行domain generalization

  - BMVC-21 [Dynamic Feature Alignment for Semi-supervised Domain Adaptation](https://arxiv.org/abs/2110.09641)
    - Dynamic feature alignment for semi-supervised DA
    - 动态特征对齐用于半监督DA

  - NeurIPS-21 [FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling](https://arxiv.org/abs/2110.08263) [知乎解读](https://zhuanlan.zhihu.com/p/422930830) [code](https://github.com/TorchSSL/TorchSSL)
    - Curriculum pseudo label with a unified codebase TorchSSL
    - 半监督方法FlexMatch和统一算法库TorchSSL

  - [Rethinking supervised pre-training for better downstream transferring](https://arxiv.org/abs/2110.06014)
    - Rethink better finetune
    - 重新思考预训练以便更好finetune

  - [Music Sentiment Transfer](https://arxiv.org/abs/2110.05765)
    - Music sentiment transfer learning
    - 迁移学习用于音乐sentiment

  - NeurIPS-21 [Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data](http://arxiv.org/abs/2110.03374)
    - Source-free domain adaptation using constrastive learning
    - 无源域数据的DA，利用对比学习

  - [Understanding Domain Randomization for Sim-to-real Transfer](http://arxiv.org/abs/2110.03239)
    - Understanding domain randomizationfor sim-to-real transfer
    - 对强化学习中的sim-to-real transfer进行理论上的分析

  - [Dynamically Decoding Source Domain Knowledge For Unseen Domain Generalization](http://arxiv.org/abs/2110.03027)
    - Ensemble learning for domain generalization
    - 用集成学习进行domain generalization

  - [Scale Invariant Domain Generalization Image Recapture Detection](http://arxiv.org/abs/2110.03496)
    - Scale invariant domain generalizaiton
    - 尺度不变的domain generalization

## 2021-09

  - IEEE TIP-21 [Joint Clustering and Discriminative Feature Alignment for Unsupervised Domain Adaptation](https://ieeexplore.ieee.org/abstract/document/9535218)
    - Clustering and discriminative alignment for DA
    - 聚类与判定式对齐用于DA

  - IEEE TNNLS-21 [Entropy Minimization Versus Diversity Maximization for Domain Adaptation](https://ieeexplore.ieee.org/abstract/document/9537640)
    - Entropy minimization versus diversity max for DA
    - 熵最小化与diversity最大化

  - [Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation](https://arxiv.org/abs/2109.11798)
    - Adversarial domain adaptation for bronchoscopic depth estimation
    - 用对抗领域自适应进行支气管镜的深度估计

  - EMNLP-21 [Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning](https://arxiv.org/abs/2109.06349)
    - Few-shot intent detection using pretrain and finetune
    - 用迁移学习进行少样本意图检测

  - EMNLP-21 [Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation](https://arxiv.org/abs/2109.06604)
    - UDA for machine translation
    - 用领域自适应进行机器翻译

  - [KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation](https://arxiv.org/abs/2109.06243)
    - Using Kronecker decomposition and knowledge distillation for pre-trained language models compression
    - 用Kronecker分解和知识蒸馏来进行语言模型的压缩

  - [Cross-Region Domain Adaptation for Class-level Alignment](https://arxiv.org/abs/2109.06422)
    - Cross-region domain adaptation for class-level alignment
    - 跨区域的领域自适应用于类级别的对齐

  - [Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning](https://arxiv.org/abs/2109.05664)
    - Domain adaptation for cross-modality liver segmentation
    - 使用domain adaptation进行肝脏的跨模态分割

  - [CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation](https://arxiv.org/abs/2109.06165)
    - Cross-domain transformer for domain adaptation
    - 基于transformer进行domain adaptation

  - ICCV-21 [Shape-Biased Domain Generalization via Shock Graph Embeddings](https://arxiv.org/abs/2109.05671)
    - Domain generalization based on shape information
    - 基于形状进行domain generalization

  - [Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2109.05676)
    - Domain generalization for medical image segmentation
    - 领域泛化用于医学图像分割

  - [Class-conditioned Domain Generalization via Wasserstein Distributional Robust Optimization](https://arxiv.org/abs/2109.03676)
    - Domain generalization with wasserstein DRO
    - 使用Wasserstein DRO进行domain generalization

  - [FedZKT: Zero-Shot Knowledge Transfer towards Heterogeneous On-Device Models in Federated Learning](https://arxiv.org/abs/2109.03775)
    - Zero-shot transfer in heterogeneous federated learning
    - 零次迁移用于联邦学习

  - [Fishr: Invariant Gradient Variances for Out-of-distribution Generalization](https://arxiv.org/abs/2109.02934)
    - Invariant gradient variances for OOD generalization
    - 不变梯度方差，用于OOD

  - [How Does Adversarial Fine-Tuning Benefit BERT?](https://arxiv.org/abs/2108.13602)
    - Examine how does adversarial fine-tuning help BERT
    - 探索对抗性finetune如何帮助BERT

  - [Contrastive Domain Adaptation for Question Answering using Limited Text Corpora](https://arxiv.org/abs/2108.13854)
    - Contrastive domain adaptation for QA
    - QA任务中应用对比domain adaptation

## 2021-08

  - [Robust Ensembling Network for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.09473)
    - Ensembling network for domain adaptation
    - 集成嵌入网络用于domain adaptation

  - [Federated Multi-Task Learning under a Mixture of Distributions](https://arxiv.org/abs/2108.10252)
    - Federated multi-task learning
    - 联邦多任务学习

  - [Fine-tuning is Fine in Federated Learning](http://arxiv.org/abs/2108.07313)
    - Finetuning in federated learning
    - 在联邦学习中进行finetune

  - [Federated Multi-Target Domain Adaptation](http://arxiv.org/abs/2108.07792)
    - Federated multi-target DA
    - 联邦学习场景下的多目标DA

  - [Learning Transferable Parameters for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.06129)
    - Learning partial transfer parameters for DA
    - 学习适用于迁移部分的参数做UDA任务

  - MICCAI-21 [A Systematic Benchmarking Analysis of Transfer Learning for Medical Image Analysis](https://arxiv.org/abs/2108.05930)
    - A benchmark of transfer learning for medical image
    - 一个详细的迁移学习用于医学图像的benchmark

  - [TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.05988)
    - Vision transformer for domain adaptation
    - 用视觉transformer进行DA

  - CIKM-21 [AdaRNN: Adaptive Learning and Forecasting of Time Series](https://arxiv.org/abs/2108.04443) [Code](https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn) [知乎文章](https://zhuanlan.zhihu.com/p/398036372) [Video](https://www.bilibili.com/video/BV1Gh411B7rj/)
    - A new perspective to using transfer learning for time series analysis
    - 一种新的建模时间序列的迁移学习视角

  - TKDE-21 [Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals](https://arxiv.org/abs/2107.12626)
    - Anomaly detection using semi-supervised and transfer learning
    - 半监督学习用于无监督异常检测

  - SemDIAL-21 [Generating Personalized Dialogue via Multi-Task Meta-Learning](https://arxiv.org/abs/2108.03377)
    - Generate personalized dialogue using multi-task meta-learning
    - 用多任务元学习生成个性化的对话

  - ICCV-21 [BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation](https://arxiv.org/abs/2108.03267)
    - Bijective MMD for domain adaptation
    - 双射MMD用于语义分割

  - [A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions](https://arxiv.org/abs/2108.03357)
    - A survey on cross-domain recommendation
    - 跨领域的推荐的综述

  - [A Data Augmented Approach to Transfer Learning for Covid-19 Detection](https://arxiv.org/abs/2108.02870)
    - Data augmentation to transfer learning for COVID
    - 迁移学习使用数据增强，用于COVID-19

  - MM-21 [Few-shot Unsupervised Domain Adaptation with Image-to-class Sparse Similarity Encoding](https://arxiv.org/abs/2108.02953)
    - Few-shot DA with image-to-class sparse similarity encoding
    - 小样本的领域自适应

  - [Dual-Tuning: Joint Prototype Transfer and Structure Regularization for Compatible Feature Learning](https://arxiv.org/abs/2108.02959)
    - Prototype transfer and structure regularization
    - 原型的迁移学习

  - [Finetuning Pretrained Transformers into Variational Autoencoders](https://arxiv.org/abs/2108.02446)
    - Finetune transformer to VAE
    - 把transformer迁移到VAE

  - [Pre-trained Models for Sonar Images](http://arxiv.org/abs/2108.01111)
    - Pre-trained models for sonar images
    - 针对声纳图像的预训练模型

  - [Domain Adaptor Networks for Hyperspectral Image Recognition](http://arxiv.org/abs/2108.01555)
    - Finetune for hyperspectral image recognition
    - 针对高光谱图像识别的迁移学习

## 2021-07

  - CVPR-21 [Efficient Conditional GAN Transfer With Knowledge Propagation Across Classes](https://openaccess.thecvf.com/content/CVPR2021/html/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.html)
    - Transfer conditional GANs to unseen classes
    - 通过知识传递，迁移预训练的conditional GAN到新类别

  - CVPR-21 [Ego-Exo: Transferring Visual Representations From Third-Person to First-Person Videos](https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ego-Exo_Transferring_Visual_Representations_From_Third-Person_to_First-Person_Videos_CVPR_2021_paper.html)
    - Transfer learning from third-person to first-person video
    - 从第三人称视频迁移到第一人称

  - [Toward Co-creative Dungeon Generation via Transfer Learning](http://arxiv.org/abs/2107.12533)
    - Game scene generation with transfer learning
    - 用迁移学习生成游戏场景

  - [Transfer Learning in Electronic Health Records through Clinical Concept Embedding](https://arxiv.org/abs/2107.12919)
    - Transfer learning in electronic health record
    - 迁移学习用于医疗记录管理

  - CVPR-21 [Conditional Bures Metric for Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Conditional_Bures_Metric_for_Domain_Adaptation_CVPR_2021_paper.html)
    - A new metric for domain adaptation
    - 提出一个新的metric用于domain adaptation

  - CVPR-21 [Wasserstein Barycenter for Multi-Source Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2021/html/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html)
    - Use Wasserstein Barycenter for multi-source domain adaptation
    - 利用Wasserstein Barycenter进行DA

  - CVPR-21 [Generalized Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2021/html/Mitsuzumi_Generalized_Domain_Adaptation_CVPR_2021_paper.html)
    - A general definition for domain adaptation
    - 一个更抽象更一般的domain adaptation定义

  - CVPR-21 [Reducing Domain Gap by Reducing Style Bias](https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Reducing_Domain_Gap_by_Reducing_Style_Bias_CVPR_2021_paper.html)
    - Syle-invariant training for adaptation and generalization
    - 通过训练图像对style无法辨别来进行DA和DG

  - CVPR-21 [Uncertainty-Guided Model Generalization to Unseen Domains](https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_Uncertainty-Guided_Model_Generalization_to_Unseen_Domains_CVPR_2021_paper.html)
    - Uncertainty-guided generalization
    - 基于不确定性的domain generalization

  - CVPR-21 [Adaptive Methods for Real-World Domain Generalization](https://openaccess.thecvf.com/content/CVPR2021/html/Dubey_Adaptive_Methods_for_Real-World_Domain_Generalization_CVPR_2021_paper.html)
    - Adaptive methods for domain generalization
    - 动态算法，用于domain generalization

  - 20210716 ICML-21 [Continual Learning in the Teacher-Student Setup: Impact of Task Similarity](https://arxiv.org/abs/2107.04384)
    - Investigating task similarity in teacher-student learning
    - 调研在continual learning下teacher-student learning问题的任务相似度

  - 20210716 BMCV-extend [Exploring Dropout Discriminator for Domain Adaptation](https://arxiv.org/abs/2107.04231)
    - Using multiple discriminators for domain adaptation
    - 用分布估计代替点估计来做domain adaptation

  - 20210716 TPAMI-21 [Lifelong Teacher-Student Network Learning](https://arxiv.org/abs/2107.04689)
    - Lifelong distillation
    - 持续的知识蒸馏

  - 20210716 MICCAI-21 [Few-Shot Domain Adaptation with Polymorphic Transformers](https://arxiv.org/abs/2107.04805)
    - Few-shot domain adaptation with polymorphic transformer
    - 用多模态transformer做少样本的domain adaptation

  - 20210716 InterSpeech-21 [Speech2Video: Cross-Modal Distillation for Speech to Video Generation](https://arxiv.org/abs/2107.04806)
    - Cross-model distillation for video generation
    - 跨模态蒸馏用于语音到video的生成

  - 20210716 ICML-21 workshop [Leveraging Domain Adaptation for Low-Resource Geospatial Machine Learning](https://arxiv.org/abs/2107.04983)
    - Using domain adaptation for geospatial ML
    - 用domain adaptation进行地理空间的机器学习 